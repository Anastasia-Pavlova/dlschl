{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Школа глубокого обучения\n",
    "\n",
    "<a href=\"https://mipt.ru/science/labs/laboratoriya-neyronnykh-sistem-i-glubokogo-obucheniya/\"><img align=\"right\" src=\"https://avatars1.githubusercontent.com/u/29918795?v=4&s=200\" alt=\"DeepHackLab\" style=\"position:relative;top:-40px;right:10px;height:100px;\" /></a>\n",
    "\n",
    "\n",
    "### Физтех-Школа Прикладной математики и информатики МФТИ \n",
    "### Лаборатория нейронных сетей и глубокого обучения (DeepHackLab)\n",
    "*Дедлайн -- 30 апреля* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Захаркин Илья (ФИВТ МФТИ)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Автоэнкодеры  \n",
    "(основано на [этом цикле статей на Хабрахабре](https://habrahabr.ru/post/331382/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/cvae_meme.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добро пожаловать в (условно) 4-ую часть нашего курса Deep Learning School - \"Neural Unsupervised learning and Generative models\"!  \n",
    "Сейчас будет много текста (но он очень полезен!!), просьба всё прочитать и не забывать отвечать на вопросы, они стоят баллы ;)\n",
    "\n",
    "Набравшись опыта в задачах **supervised learning** (обучения с учителем), где нам всегда были даны объекты из обучающей выборки и истинные значения целевой переменной а них (будь то номер класса в задачах классификации; bounding box'ы в задачах детектирования объектов; текст, написанный человеком, в задачах language modelling), время окунуться в другую часть машинного обучения (и глубокого обучения, в частности) - **unsupervised learning** (обучение без учителя), где истинные ответы на объектах отсутствуют.  \n",
    "\n",
    "Примеры задач обучения без учителя:  \n",
    "* **Задача понижения размерности**: Нужно уменьшить размерность признакового пространства так, чтобы сохранить максимум информации о признаках/объектах\" (см. [PCA](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82), [t-SNE](https://habrahabr.ru/post/267041/))  \n",
    "* **Задача кластеризации**: Есть много данных о пользователях, посещающих сайт, необходимо сформировать из всех этих пользователей несколько групп (их количество может быть задан, а может быть неизвестно), в которых лежащие в каждой группе пользователи будут похожи между собой (похожесть будет определяться алгоритмом исходя из значений признаков у каждого объекта (см. [KMeans](https://habrahabr.ru/post/67078/), [DBSCAN](https://habrahabr.ru/post/322034/))  \n",
    "\n",
    "*Стоит отметить, что многие задачи, встречающиеся в жизни, могут быть решены как с помощью supervised, так и с помощью  unsupervised подходов. Эти методы не являются строгим разделением машинного обучения, поскольку unsupervised задача, по сути, более общая. Это довольно похожие, но в то же время разные задачи, решающиеся с одной стороны похожими методами оптимизации, с другой стороны - в их основе лежат разные идеи и принципы. Если хочется больше узнать об supervised и unsupervised подходах в целом, просьба **СДЕЛАТЬ ЧТО???***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/clustering_examples.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пара слов о генеративных моделях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша цель по окончание этого блока курса - понять, как работают генеративные сети (generative nets/models), что они могут, а чего пока что не могут, и почему они на волне хайпа в последнее время (немного погуглив можно убедиться, что сейчас в сфере DL больше всего в тренде как раз GAN'ы и Reinforcement Learning).  \n",
    "\n",
    "На вторые два вопроса (применение и почему хайп) ответить не очень сложно - популярность вызвана как раз-таки преимущественно пимерами использования, а именно:\n",
    "* [Генерация лиц людей, выглядящих совсем как настоящие](https://trashbox.ru/topics/113752/nejroset-nvidia-sozdaet-realistichnye-fotografii-lyudej)  \n",
    "* [Задача улучшения качества картинки (superresolution)](https://github.com/tensorlayer/srgan)  \n",
    "* [Перенос стиля и отдельных объектов с одной картинки (видео) на другую картинку (видео) с помощью CycleGAN](https://junyanz.github.io/CycleGAN/)\n",
    "* Перенос лиц людей с одной картинки (видео) на другую картинку (видео)\n",
    "* [Генерация картинки по тексту (Text2Pix)](https://github.com/reedscot/icml2016)\n",
    "* [Генерация картинки из рисунка (Pix2Pix)](https://github.com/phillipi/pix2pix)\n",
    "\n",
    "..и многие другие [примеры применения GAN'ов](https://github.com/nashory/gans-awesome-applications)  \n",
    "\n",
    "Саму модель (архитектуру нейросети) GAN (*Generative Adversarial Network - Генеративная состязательная сеть*) - придумал Ian Goodfellow в 2014 году."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/gans_from_noise.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. если Вам уже не терпится узнать о GAN'ах побольше, можете начать с [этого поста](https://blog.statsbot.co/generative-adversarial-networks-gans-engine-and-applications-f96291965b47)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Однако стоит понимать, что все эти применения ещё далеки от идеала, и все красивые примеры были специально подобраны, причём всё это обучалось на очень хорошем железе и применяется совсем не в реальном времени (зачастую, но есть [интерактинвые применения GAN'ов в реальном времени](https://github.com/junyanz/iGAN)). Поэтому не стоит думать, что всё так просто и можно качестсвенно и быстро генерировать лица людей и переносить стиль - люди, которые действительно умеют довести эту технологию до работы в реальном продакшене, очень редки.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но перед GAN'ами давайте разберёмся в автоэнкодерах - они, конечно, не так используюстя в генерации, но зато в них заложены похожие принципы и у них тоже есть применения:  \n",
    "\n",
    "* Предобучение, например, когда стоит задача классификации, а размеченных пар слишком мало  \n",
    "* Понижения размерности в данных для последующей визуализации  \n",
    "* Надо научиться различать полезные свойства входного сигнала\n",
    "\n",
    "А с помощью VAE (Variational AutoEncoders) тоже можно генерировать новые объекты, прямо как с помощью GAN'ов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/ae_vae.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: *Что делает автоэнкодер?*  \n",
    "**Ответ**: *Выучивает представление объектов из обучающей выборки в пространстве признаков более низкой размерности (по сравнению с изначальной) путём обучения нейросети как можно более точно восстановить входящий объект. То есть на вход, например, подаём картинку, цель нейросети - выдать в качестве предсказания эту же картинку.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналогия с Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Выучивает представление объектов из обучающей выборки в пространстве признаков более низкой размерности...\" - ничего не напоминает? :)  \n",
    "\n",
    "Чем то похожим мы занимались, когда говорили об эмбеддингах - представлениях слов в пространстве некоторой размерности, так, чтобы \"похожие\" слова находились как можно \"ближе\" в этом пространстве. Однако там функция потерь (loss) была построена таким образом, и сам алгоритм устроен таким образом, что это была задача на стыке supervised и unsuoervised - есть слова, и есть контексты, в которых они встречаются. Loss мерил, насколько плохо мы предсказываем вероятность слову появиться в этом контексе (см. [Видеолекция DLSchool](https://www.youtube.com/watch?v=ufkDhrngcr0), [Word2Vec](https://ru.wikipedia.org/wiki/Word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/word2vec.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос (0.5 баллов)**: А в каком пространстве признаков мы представляем слова, когда используем *bag of words*? Опишите это пространство (имеется в виду: как в нём представляются слова и сколько в нём объектов).  \n",
    "**Ваш Ответ:** <Ваш ответ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда нужно выучить **более низкоразмерное представление**, скажем, **картинок**, речи о контексте не идёт - это, конечно, теоретически возможный подход (хотя что такое контекст картинки? есть ли он у всех картинок? если не у всех, то как учить/предсказывать?), но всё же данные изображения имеют иную природу (ведь текст сам по себе имеет зависимости слов друг от друга (*sequential data*), а *картинки - в целом независимы*, ведь мы не употребляем их в виде осмысленных последовательносей картинок одной и другой (можете писать все ваши мысли по этому поводу в этом ноутбуке, вдруг придумаете что-то своё очень крутое ;) ))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Autoencoders, sparse autoencoders, denoising autoencoders](https://en.wikipedia.org/wiki/Autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взять и выдать входную картинку - бессмысленно, так мы ничего не добьёмся. Мы хотим выучить по сути эмбеддинг картинки. Чтобы сеть не могла сразу вывести вход, на неё накладывают различные ограничения:  \n",
    "* Уменьшают количество признаков (общая идея автоэнкодеров), то есть количество нейронов в скрытом слое автоэнкодера\n",
    "* Запрещают слишком многим нейронам реагировать (\"загораться\") на входы, делая таким образом сеть \"разреженной\" (разреженный, или sparse автоэнкодер)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/ae_structure.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке Вы самостоятельно реализуете 4 вида автоэнкодеров (не бойтесь, они все действительно несложно пишутся, особенно на фреймворке) с помощью PyTorch:  \n",
    "0). ***Неглубокий сжимающий автоэнкодер*** (уже написан в качестве примера)  \n",
    "1). ***Глубокий автоэнкодер*** (2 балла)  \n",
    "2). ***Свёрточный автоэнкодер*** (2 балла)  \n",
    "3). ***Очищающий от шума (Denoising) автоэнкодер*** (2 балла)  \n",
    "4). ***Разреженный (Sparse) автоэнкодер*** (2 балла)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За выполнение каждого из пунктов будут баллы, так что максимальная сумма = 8, плюс будут вопросы, отвечая на которые Вы можете заработать ещё 2 балла. Максимум за задание - 10 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренироваться и предсказывать будем по-классике - на датасете **MNIST**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужные библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если что-то отстутствует, [вот инструкция](https://github.com/deepmipt/dlschl/wiki/%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%86%D0%B8%D1%8F-%D0%BF%D0%BE-%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B5-PyTorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сжимающий (undercomplete) автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно, он выглядит очень просто:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./__pics__/simple_ae.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Стандратная предобработка MNIST-картинок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataset = MNIST('./data', download=True, transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос на понимание (0.5 баллов)**: Что делает код выше? (напишите комментарий к каждой строке кода)  \n",
    "**Ответ**: <Напишите комментарий к каждой строке кода ячейки выше>  \n",
    "\n",
    "*Подсказка: посмотрите ноутбук про Transfer Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Архитектура модели - ничего сложного, два слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential-способ построения модели\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        # сожмём картинку 28х28 в 128-мерное пространство\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128)\n",
    "        )\n",
    "        # разожмём картинку из 128-мерного пространства обратно в 28х28\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 28 * 28), \n",
    "            nn.Sigmoid()  # между 0 и 1 - интенсивность картинки\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Проверим, есть ли cuda (доступный GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если выдаёт не 0, то можно использовать GPU, и везде, где в комментарии стоит .cuda(), можно её включить (раскомментировав)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Конфигурируем, задаём лосс - в данном случае используется MSE, но можно и Log Loss, поскольку мы выдаём ответы сигмоидой (от 0 до 1). Так и будет обучаться модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "model = autoencoder()#.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Что в итоге получилось (нейросеть):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Обучаем, подавая на вход картинки и штрафуя за отклонения от них же (тут канал только 1, характеризуется интенсивностью; можно выдавать от 0 до 255 на все три канала, это будет штраф для обычных цветных картинок):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 25  # без GPU будет обучаться не меньше 20 минут\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)#.cuda()\n",
    "        # forward pass\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # logging info\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        # для наглядности того, насколько автоэнкодер \n",
    "        # сейчас хорошо восстанавливает картинку\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './simple_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посмотреть на текущий результат, нужно посмотреть на качество картинок в папке `./mlp_img` - это то, как автоэнкодер сейчас восстанавливает входную картинку (там сразу батчами по batch_size штук)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но можно попробовать и здесь отрисовать результат, если хочется.  \n",
    "Функция для отрисовки картинок из ответов сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# взято из статьи с Хабрахабра\n",
    "def plot_digits(*args):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    \n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\n",
    "    for j in range(n):\n",
    "        for i in range(len(args)):\n",
    "            ax = plt.subplot(len(args), n, i*n + j + 1)\n",
    "            plt.imshow(args[i][j])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят восстановленные из низкоразмерных представлений картинки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывести предсказания энкодера на картинках (1 бонусный балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось неплохо. Но Вы сможете лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие пункты нужно реализовать Вам, а поможет [эта статья](https://habrahabr.ru/post/331382/) (на ней и основана эта домашка, как говорилось уже много раз) и [этот код](https://blog.keras.io/building-autoencoders-in-keras.html). **Вам нужно реализовать всё строго на PyTorch**.  \n",
    "Просьба всё же проявить энтузиазм и пытаться писать самому, сильно не подглядывая. Это интереснее и полезнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глубокий (deep) автоэнкодер (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<Проделайте всё то же самое, что и для сжимающего, но только теперь для глубокого>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Свёрточный (convolutional) автоэнкодер (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<Проделайте всё то же самое, что и для сжимающего, но только теперь для свёрточного>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очищающий от шума (denoising) автоэнкодер (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<Проделайте всё то же самое, что и для сжимающего, но только теперь для denoising>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разреженный (sparse) автоэнкодер (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<Проделайте всё то же самое, что и для сжимающего, но только теперь для разреженного>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос (1 балл):** Какой из автоэнкодеров отработал лучше всего (судя о значению loss'а)? Почему, как вы думаете? Дайте максимально развёрнутый ответ.  \n",
    "**Ответ:** <Ваш ответ здесь>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Где почитать про это:\n",
    "\n",
    "- [Да-да, тот самый цикл статей на Хабре, он правда хороший :)](https://habrahabr.ru/post/331382/)  \n",
    "- [От Стэнфорда (на английском)](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)\n",
    "- [Презентация (на английском) на сайте machinelearning.ru](http://www.machinelearning.ru/wiki/images/5/54/DL16_lecture_9.pdf)\n",
    "- [Код всех видов автоэнкодеров на Keras](https://blog.keras.io/building-autoencoders-in-keras.html)  \n",
    "- [Бегиннерс гайд](https://deeplearning4j.org/deepautoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ждём на последующих занятиях ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
