{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Школа глубокого обучения\n",
    "\n",
    "<a href=\"https://mipt.ru/science/labs/laboratoriya-neyronnykh-sistem-i-glubokogo-obucheniya/\"><img align=\"right\" src=\"https://avatars1.githubusercontent.com/u/29918795?v=4&s=200\" alt=\"DeepHackLab\" style=\"position:relative;top:-40px;right:10px;height:100px;\" /></a>\n",
    "\n",
    "\n",
    "\n",
    "### Физтех-Школа Прикладной математики и информатики МФТИ \n",
    "### Лаборатория нейронных сетей и глубокого обучения (DeepHackLab)\n",
    "*Дедлайн -- 18 марта.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Червонцев Сергей (ФИВТ МФТИ)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Привет! В этом задании мы будем предсказывать персонажа Южного парка по его фразе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В задании четыре пункта, за которые суммарно можно получить 12 баллов. При этом максимум за задание - 10 баллов. Поэтому некоторые пункты можно пропустить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сперва скачаем размечанные [диалоги из Южного Парка](https://www.kaggle.com/tovarischsukhov/southparklines/data) и изучим их. Для работы с таблицами нам потребуется [pandas](https://pandas.pydata.org/pandas-docs/stable/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, re, random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
       "1     10       1      Kyle                        Going away? For how long?\\n\n",
       "2     10       1      Stan                                         Forever.\\n\n",
       "3     10       1      Chef                                  I'm sorry boys.\\n\n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('All-seasons.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3950</td>\n",
       "      <td>64301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Cartman</td>\n",
       "      <td>What?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6416</td>\n",
       "      <td>5271</td>\n",
       "      <td>9774</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season Episode Character     Line\n",
       "count   70896   70896     70896    70896\n",
       "unique     19      19      3950    64301\n",
       "top         2      10   Cartman  What?\\n\n",
       "freq     6416    5271      9774      361"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В нашем распоряжении ~70к фраз от ~4к персонажей с первого по восемнадцатый сезоны. Выкинем всех второстепенных персонажей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character\n",
      "Cartman         9774\n",
      "Stan            7680\n",
      "Kyle            7099\n",
      "Butters         2602\n",
      "Randy           2467\n",
      "Mr. Garrison    1002\n",
      "Chef             917\n",
      "Kenny            881\n",
      "Sharon           862\n",
      "Name: Line, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# немного магии\n",
    "lines_freqs = raw_df.groupby(['Character'])['Line'].count()\n",
    "# оставляем персонажей, у которых больше восьмиста реплик\n",
    "desired_freqs = (lines_freqs > 800)\n",
    "main_characters = lines_freqs[desired_freqs].sort_values(ascending=False)\n",
    "df = raw_df.loc[raw_df['Character'].isin(main_characters.keys())].copy()\n",
    "character_to_id = {c: i for i,c in enumerate(main_characters.keys())}\n",
    "print(main_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33284, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# число оставшихся примеров\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Теперь нам нужно сделать *токенизацию* - проще говоря, разбить каждое предложение на отдельные слова, выкинув ненужные символы вроде \"/n\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "----------\n",
      "What's the matter, Mr. Hankey? Are you sick?\n",
      "\n",
      "----------\n",
      "Tokenized:\n",
      "----------\n",
      "['what', 's', 'the', 'matter', ',', 'mr', '.', 'hankey', '?', 'are', 'you', 'sick', '?'] "
     ]
    }
   ],
   "source": [
    "def tokenize_phrase(phrase_as_str):\n",
    "    # ещё немного магии\n",
    "    # r'\\w+|\\?|\\!|,|\\.' значит извлечь все слова и знаки \"?\",\"!\",\",\",\".\"\n",
    "    # r'\\w+' значит извлечь все слова\n",
    "    # r'\\w+|\\.' значит извлечь все слова и знаки \".\"\n",
    "    # ... ну вы поняли\n",
    "    # уберите .lower(), чтобы слова типо \"What\" не преобразовывались в \"what\"\n",
    "    return re.findall(r'\\w+|\\?|\\!|,|\\.', phrase_as_str.lower())\n",
    "\n",
    "# проверим на случайном примере, что всё хорошо\n",
    "rand_ex = df['Line'].sample().values[0]\n",
    "print('Original:')\n",
    "print('-'*10)\n",
    "print(rand_ex)\n",
    "print('-'*10)\n",
    "print('Tokenized:')\n",
    "print('-'*10)\n",
    "print(tokenize_phrase(rand_ex), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "      <th>Tokenized Line</th>\n",
       "      <th>Character Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "      <td>[you, guys, ,, you, guys, !, chef, is, going, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "      <td>[going, away, ?, for, how, long, ?]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "      <td>[forever, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "      <td>[i, m, sorry, boys, .]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "      <td>[chef, said, he, s, been, bored, ,, so, he, jo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line  \\\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n   \n",
       "1     10       1      Kyle                        Going away? For how long?\\n   \n",
       "2     10       1      Stan                                         Forever.\\n   \n",
       "3     10       1      Chef                                  I'm sorry boys.\\n   \n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro...   \n",
       "\n",
       "                                      Tokenized Line  Character Id  \n",
       "0  [you, guys, ,, you, guys, !, chef, is, going, ...             1  \n",
       "1                [going, away, ?, for, how, long, ?]             2  \n",
       "2                                       [forever, .]             1  \n",
       "3                             [i, m, sorry, boys, .]             6  \n",
       "4  [chef, said, he, s, been, bored, ,, so, he, jo...             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# токенизируем каждую реплику\n",
    "df['Tokenized Line'] = df['Line'].apply(lambda row: tokenize_phrase(row))\n",
    "raw_df['Tokenized Line'] = raw_df['Line'].apply(lambda row: tokenize_phrase(row))\n",
    "\n",
    "df['Character Id'] = df['Character'].apply(lambda row: character_to_id[row])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJQAAAJCCAYAAACWHZ1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01727819e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# считаем число \"слов\" в каждой реплике\n",
    "words_len = df['Tokenized Line'].apply(lambda row: len(row))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(words_len, bins=200)\n",
    "plt.xlim((0,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# разбиваем данные на трейн и тест\n",
    "train_df = df.sample(frac=0.85,random_state=200)\n",
    "test_df = df.drop(train_df.index)\n",
    "MAX_LEN = max([len(l) for l in df['Tokenized Line']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Итак, мы решаем задачу классификации преимущественно коротких фраз (как видно из графика выше) на большое количество классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Обучение FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "На прошлой лекции вы познакомились со схемой word2vec.\n",
    "\n",
    "Для её обучения на наших конкретных данных нужно:\n",
    "1. Склеить всё, что можно, в единый массив текста - *корпус*.\n",
    "2. Проиндексировать слова в корпусе, выкинув слишком редкие.\n",
    "3. Сделать генерацию примеров для обучения.\n",
    "4. Реализовать cbow (предсказание центрального слова по контексту) или skip-gram (наоборот).\n",
    "5. Обучить на корпусе и проверить корректность полученных векторов.\n",
    "\n",
    "Основная проблема в таком подходе - время. В [самой лучшей](https://arxiv.org/abs/1712.09405) на обучение векторов тратится примерно три дня, при этом используется масса ухищрений и оптимизаций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Можно было бы взять готовый word2vec и доучить его на наших данных, или использовать [tf-idf](https://www.kaggle.com/agaleana/predicting-south-park-dialogues), но мы пойдём другим путём.\n",
    "\n",
    "А именно, напишем очень простую, но эффективную для классификации модель - [FastText](https://arxiv.org/abs/1607.01759).\n",
    "\n",
    "Вся суть описывается картинкой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"http://wellyzhang.github.io/img/in-post/fastText/model.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Где output - это вектор размерности (в нашем случае) девять, отвечающий каждому классу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В задании предлагается написать свой FastText, а также ответить на несколько вопросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1. Реализуйте FastText на девять классов(с обычным softmax). В качестве ошибки для обучения используете [Negative Log Likelihood](http://pytorch.org/docs/master/nn.html#nllloss). (5 баллов)\n",
    "2. Как влияет на качество учёт знаков препинания и \"мусорных\" слов (предлогов, междометий), а также больших букв? Сравните качество модели в трёх случаях: со всеми словами и символами, без частых слов и символов (используйте nltk.corpus.stopwords) и без редких слов. Сделайте выводы. (2 балла)\n",
    "3. В чём причина низкого качества решения? Приведите несколько примеров, на которых модель ошибается, и предложите, как можно её улучшить (2 балла).\n",
    "4. Получите accuracy не ниже 42% на данных (вам поможет инициализация, dropout, а также [subsampling](https://arxiv.org/abs/1712.09405) (случайное удаление слов с вероятностью $\\sqrt(\\frac{1}{p(w)}),$ где $p(w)$ - частота, с которой встречается слово)) (3 балла). Если получите качество выше 50% (не меняя ничего в первой части) - 10 баллов автоматом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it s true . but are you back for good ? that s right . hey everybody ! chef s back ! what ? all right ! yeah ! oh , finally ! wow ! it seems like you had a great time with the super adventure club , chef . they sound like really interesting people . yeah ! but now that you re back here , does that mean that you re not in the super adventure club anymore ? nnono ! ohhh , so have you decided you can still belong to the super adventure club but\n"
     ]
    }
   ],
   "source": [
    "# собираем корпус фраз\n",
    "raw_corpus = []\n",
    "# параллельно запоминаем словарь слов\n",
    "raw_words_set = set()\n",
    "\n",
    "for line in raw_df['Tokenized Line']:\n",
    "    raw_corpus += line\n",
    "    raw_words_set |= set(line)\n",
    "\n",
    "print(' '.join(raw_corpus[234:334]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab_size: 25063\n"
     ]
    }
   ],
   "source": [
    "words_set = raw_words_set\n",
    "words_set |= set(['<end>'])\n",
    "# некоторые из слов здесь можно выбросить\n",
    "print('Vocab_size:', len(words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# индексируем слова\n",
    "id_to_word = {i: word for i, word in enumerate(words_set)}\n",
    "word_to_id = {word: i for i, word in enumerate(words_set)}\n",
    "\n",
    "# corpus - вектор натуральных чисел от 0 до vocab_size \n",
    "corpus = np.array([word_to_id[word] for word in raw_corpus if word in words_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_phrase(phrase):\n",
    "    # преобразование фразы в id-шники\n",
    "    processed = [word_to_id['<end>']] * MAX_LEN\n",
    "    for index, word in enumerate(phrase):\n",
    "        if word in words_set:\n",
    "            processed[index] = word_to_id[word]\n",
    "    return processed\n",
    "\n",
    "def sample_batch(df, batch_size=32, offset=None):\n",
    "    # генерация примеров\n",
    "    if offset is None:\n",
    "        batch = df.sample(n=batch_size)\n",
    "    else:\n",
    "        batch = df.iloc[range(offset, \n",
    "                              min(offset + batch_size, len(df)))]\n",
    "    phrases = batch['Tokenized Line'].values\n",
    "    \n",
    "    X_batch = np.array([process_phrase(phrase) for phrase in phrases])\n",
    "    y_batch = batch['Character Id'].values\n",
    "    phrase_lengths = np.array([len(phrase) for phrase in phrases])\n",
    "    return X_batch, y_batch, phrase_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', 'my', 'got', ',', 'they', 've', 'killed', 'kenny', '!', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>'] ... 381\n"
     ]
    }
   ],
   "source": [
    "ex_process = process_phrase(['oh', 'my', 'got', ',', 'they', 've', 'killed', 'kenny', '!'])\n",
    "print([id_to_word[temp] for temp in ex_process][:30], '...', len(ex_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FastTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, n_classes):\n",
    "        super(FastTextClassifier, self).__init__()\n",
    "        <эмбеддинги из индексов в нужную размерность>\n",
    "        <линейное преобразование>\n",
    "        <инициализация весов>\n",
    "    \n",
    "    def init_emb(self, embed_dim, n_classes):\n",
    "        <веса инициализируете так>\n",
    "        my_layer.weight.data.uniform(-value, value)\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "        <получаем ненормированный score>\n",
    "        <передаём в лог-софтмакс для использования в NLLLoss>\n",
    "        return F.log_softmax(my_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy(df, model):\n",
    "    # число правильных ответов модели\n",
    "    cbatch_size = 32\n",
    "    y_pred = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(0, len(df), cbatch_size):\n",
    "        batch_X, batch_y, batch_lengths = sample_batch(df, cbatch_size, offset=i)\n",
    "        predictions_proba = torch.exp(model(Variable(torch.LongTensor(batch_X)), \n",
    "                          Variable(torch.FloatTensor(batch_lengths))))\n",
    "        predictions = torch.max(predictions_proba, 1)[1]\n",
    "        y_pred[i:min(i+cbatch_size, len(df))] = predictions\n",
    "    return accuracy_score(y_pred, df['Character Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init accuracy: 0.17905067093931504\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = <размерность векторов>\n",
    "LR = 1e-3\n",
    "\n",
    "fast_clf = FastTextClassifier(len(words_set), EMBED_DIM, len(main_characters))\n",
    "loss_function = <neg log likelihood>\n",
    "optimizer = <adam>\n",
    "\n",
    "print('Init accuracy:', get_accuracy(test_df, fast_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "AVG LOSSS: 1.841685851774604\n",
      "TEST ACCURACY: 0.3128379731624274\n",
      "----------\n",
      "EPOCH: 1\n",
      "AVG LOSSS: 1.7642229865579044\n",
      "TEST ACCURACY: 0.3228519927899059\n",
      "----------\n",
      "EPOCH: 2\n",
      "AVG LOSSS: 1.6911333869485294\n",
      "TEST ACCURACY: 0.36611255758061284\n",
      "----------\n",
      "EPOCH: 3\n",
      "AVG LOSSS: 1.6118695703566883\n",
      "TEST ACCURACY: 0.3566993791307831\n",
      "----------\n",
      "EPOCH: 4\n",
      "AVG LOSSS: 1.544486895945277\n",
      "TEST ACCURACY: 0.39535349489285\n",
      "----------\n",
      "EPOCH: 5\n",
      "AVG LOSSS: 1.4915567113263575\n",
      "TEST ACCURACY: 0.39114760664930903\n",
      "----------\n",
      "EPOCH: 6\n",
      "AVG LOSSS: 1.4398582769195418\n",
      "TEST ACCURACY: 0.4121770478670138\n",
      "----------\n",
      "EPOCH: 7\n",
      "AVG LOSSS: 1.3907952632299916\n",
      "TEST ACCURACY: 0.4203885439615462\n",
      "----------\n",
      "EPOCH: 8\n",
      "AVG LOSSS: 1.3481398362379808\n",
      "TEST ACCURACY: 0.41798517925095136\n",
      "----------\n",
      "EPOCH: 9\n",
      "AVG LOSSS: 1.305146644557763\n",
      "TEST ACCURACY: 0.3971560184257961\n",
      "----------\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "n_epochs = <число эпох>\n",
    "batch_size = <размер батча>\n",
    "n_steps_per_epoch = <число шагов за эпоху>\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "old_test_accuracy = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = torch.Tensor([0])\n",
    "    for i in range(n_steps_per_epoch):\n",
    "        batch_X, batch_y, batch_lengths = sample_batch(train_df, batch_size)\n",
    "        \n",
    "        fast_clf.zero_grad()\n",
    "        \n",
    "        <Получение ответов по выборке, пересчёт лосса>\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += batch_loss.data\n",
    "        losses += [batch_loss.data]\n",
    "    print('EPOCH:', epoch)\n",
    "    print('AVG LOSSS:', epoch_loss.numpy()[0] / n_steps_per_epoch)\n",
    "    test_accuracy = get_accuracy(test_df, fast_clf)\n",
    "    accuracies += [test_accuracy]\n",
    "    print('TEST ACCURACY:', test_accuracy)\n",
    "    print('-'*10)\n",
    "    if <Критерий остановки>:\n",
    "        break\n",
    "    else:\n",
    "        old_test_accuracy = test_accuracy\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.40216302823953537\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy:', get_accuracy(test_df, fast_clf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
