{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Школа глубокого обучения\n",
    "\n",
    "<a href=\"https://mipt.ru/science/labs/laboratoriya-neyronnykh-sistem-i-glubokogo-obucheniya/\"><img align=\"right\" src=\"https://avatars1.githubusercontent.com/u/29918795?v=4&s=200\" alt=\"DeepHackLab\" style=\"position:relative;top:-40px;right:10px;height:100px;\" /></a>\n",
    "\n",
    "\n",
    "\n",
    "### Физтех-Школа Прикладной математики и информатики МФТИ \n",
    "### Лаборатория нейронных сетей и глубокого обучения (DeepHackLab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Илья Захаркин (ФИВТ МФТИ)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке мы посмотрим на простой пример работы с реализацией Word2Vec из библиотеки `gensim`, а также на работу другой модели эмбеддингов - GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging\n",
    "\n",
    "# настроим запись служебной информации в файл\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать датасет **Text8**. Загрузим корпус текстов с сайта http://mattmahoney.net/dc/text8.zip (30 Mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus('./data/text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели. По-умолчанию используется реализация **skip-gram** с окном контекста *window=5*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 02:44:33,481 : INFO : collecting all words and their counts\n",
      "2018-03-07 02:44:33,487 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-07 02:44:39,123 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2018-03-07 02:44:39,125 : INFO : Loading a fresh vocabulary\n",
      "2018-03-07 02:44:39,479 : INFO : min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2018-03-07 02:44:39,480 : INFO : min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2018-03-07 02:44:39,727 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2018-03-07 02:44:39,746 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2018-03-07 02:44:39,748 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2018-03-07 02:44:39,749 : INFO : estimated required memory for 71290 words and 200 dimensions: 149709000 bytes\n",
      "2018-03-07 02:44:40,101 : INFO : resetting layer weights\n",
      "2018-03-07 02:44:41,083 : INFO : training model with 3 workers on 71290 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-07 02:44:42,092 : INFO : PROGRESS: at 1.18% examples, 727688 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:44:43,092 : INFO : PROGRESS: at 2.38% examples, 734568 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:44,097 : INFO : PROGRESS: at 3.61% examples, 745668 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:45,105 : INFO : PROGRESS: at 4.88% examples, 757031 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:46,112 : INFO : PROGRESS: at 5.94% examples, 738691 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:47,123 : INFO : PROGRESS: at 7.17% examples, 744372 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:48,133 : INFO : PROGRESS: at 8.22% examples, 730762 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:44:49,134 : INFO : PROGRESS: at 9.38% examples, 730857 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:44:50,139 : INFO : PROGRESS: at 10.48% examples, 725385 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:44:51,146 : INFO : PROGRESS: at 11.68% examples, 727738 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:44:52,162 : INFO : PROGRESS: at 12.87% examples, 728922 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:44:53,174 : INFO : PROGRESS: at 14.09% examples, 730693 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:54,182 : INFO : PROGRESS: at 15.31% examples, 732086 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:44:55,194 : INFO : PROGRESS: at 16.52% examples, 732674 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:44:56,199 : INFO : PROGRESS: at 17.72% examples, 733658 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:44:57,207 : INFO : PROGRESS: at 18.92% examples, 734044 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:44:58,210 : INFO : PROGRESS: at 20.09% examples, 733788 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:44:59,213 : INFO : PROGRESS: at 21.27% examples, 733385 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:00,219 : INFO : PROGRESS: at 22.35% examples, 729881 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:01,220 : INFO : PROGRESS: at 23.09% examples, 716605 words/s, in_qsize 3, out_qsize 0\n",
      "2018-03-07 02:45:02,231 : INFO : PROGRESS: at 24.08% examples, 711503 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:03,241 : INFO : PROGRESS: at 25.20% examples, 710914 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:45:04,251 : INFO : PROGRESS: at 26.35% examples, 711381 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:05,263 : INFO : PROGRESS: at 27.47% examples, 710793 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:06,267 : INFO : PROGRESS: at 28.62% examples, 711177 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:07,267 : INFO : PROGRESS: at 29.64% examples, 708518 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:08,273 : INFO : PROGRESS: at 30.71% examples, 707003 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:09,275 : INFO : PROGRESS: at 31.78% examples, 705696 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:45:10,276 : INFO : PROGRESS: at 32.87% examples, 704981 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:45:11,277 : INFO : PROGRESS: at 33.91% examples, 703090 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:12,282 : INFO : PROGRESS: at 35.10% examples, 704121 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:45:13,283 : INFO : PROGRESS: at 36.20% examples, 703336 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:14,285 : INFO : PROGRESS: at 37.20% examples, 700918 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:45:15,304 : INFO : PROGRESS: at 38.18% examples, 697887 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:16,321 : INFO : PROGRESS: at 39.27% examples, 697034 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:45:17,322 : INFO : PROGRESS: at 40.44% examples, 697784 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:18,331 : INFO : PROGRESS: at 41.55% examples, 697363 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:19,332 : INFO : PROGRESS: at 42.67% examples, 697284 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:20,335 : INFO : PROGRESS: at 43.81% examples, 697619 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:21,349 : INFO : PROGRESS: at 44.87% examples, 696592 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:22,360 : INFO : PROGRESS: at 45.97% examples, 696487 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:23,360 : INFO : PROGRESS: at 47.10% examples, 696881 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:24,364 : INFO : PROGRESS: at 48.27% examples, 697571 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:25,377 : INFO : PROGRESS: at 49.29% examples, 696135 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:26,387 : INFO : PROGRESS: at 50.31% examples, 694791 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:27,395 : INFO : PROGRESS: at 51.46% examples, 695298 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:28,420 : INFO : PROGRESS: at 52.43% examples, 693023 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:45:29,433 : INFO : PROGRESS: at 53.36% examples, 690547 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:30,444 : INFO : PROGRESS: at 54.44% examples, 690165 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:45:31,453 : INFO : PROGRESS: at 55.51% examples, 689341 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:32,470 : INFO : PROGRESS: at 56.67% examples, 689797 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:33,479 : INFO : PROGRESS: at 57.80% examples, 690004 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:34,501 : INFO : PROGRESS: at 58.97% examples, 690338 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:35,502 : INFO : PROGRESS: at 60.04% examples, 689861 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:36,514 : INFO : PROGRESS: at 61.15% examples, 689813 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:37,519 : INFO : PROGRESS: at 62.29% examples, 689995 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:38,525 : INFO : PROGRESS: at 63.40% examples, 689947 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:39,534 : INFO : PROGRESS: at 64.41% examples, 688849 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:45:40,551 : INFO : PROGRESS: at 65.43% examples, 687937 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:41,568 : INFO : PROGRESS: at 66.54% examples, 687976 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:42,578 : INFO : PROGRESS: at 67.57% examples, 687285 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:43,579 : INFO : PROGRESS: at 68.58% examples, 686434 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:45:44,588 : INFO : PROGRESS: at 69.66% examples, 686219 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:45,605 : INFO : PROGRESS: at 70.69% examples, 685366 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:46,605 : INFO : PROGRESS: at 71.73% examples, 684926 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:47,619 : INFO : PROGRESS: at 72.70% examples, 683584 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:48,621 : INFO : PROGRESS: at 73.51% examples, 680947 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:49,636 : INFO : PROGRESS: at 74.59% examples, 680795 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:50,641 : INFO : PROGRESS: at 75.61% examples, 679912 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:51,645 : INFO : PROGRESS: at 76.59% examples, 678832 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:52,660 : INFO : PROGRESS: at 77.45% examples, 676719 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:53,682 : INFO : PROGRESS: at 78.46% examples, 675882 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:45:54,708 : INFO : PROGRESS: at 79.41% examples, 674501 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:55,709 : INFO : PROGRESS: at 80.45% examples, 674120 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:56,724 : INFO : PROGRESS: at 81.61% examples, 674561 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:57,741 : INFO : PROGRESS: at 82.70% examples, 674488 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:45:58,742 : INFO : PROGRESS: at 83.77% examples, 674393 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:45:59,748 : INFO : PROGRESS: at 84.87% examples, 674528 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-07 02:46:00,748 : INFO : PROGRESS: at 85.68% examples, 672493 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:46:01,749 : INFO : PROGRESS: at 86.43% examples, 670054 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:46:02,754 : INFO : PROGRESS: at 87.48% examples, 669890 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:46:03,763 : INFO : PROGRESS: at 88.54% examples, 669749 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:46:04,770 : INFO : PROGRESS: at 89.64% examples, 669988 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-07 02:46:05,774 : INFO : PROGRESS: at 90.73% examples, 670147 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:46:06,785 : INFO : PROGRESS: at 91.82% examples, 670169 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:46:07,806 : INFO : PROGRESS: at 92.92% examples, 670268 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:46:08,811 : INFO : PROGRESS: at 94.00% examples, 670316 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-07 02:46:09,830 : INFO : PROGRESS: at 95.12% examples, 670428 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:46:10,841 : INFO : PROGRESS: at 96.27% examples, 670787 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:46:11,844 : INFO : PROGRESS: at 97.32% examples, 670583 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:46:12,849 : INFO : PROGRESS: at 98.34% examples, 670194 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-07 02:46:13,862 : INFO : PROGRESS: at 99.34% examples, 669578 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-07 02:46:14,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-07 02:46:14,552 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-07 02:46:14,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-07 02:46:14,557 : INFO : training on 85026035 raw words (62527602 effective words) took 93.5s, 668951 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# 3-5 минут\n",
    "model = word2vec.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что модель умеет, а именно выведем самые близкие по смыслу слова, удовлетворяющие условиям `positive` и `negative` примеров (то есть слова, близкие к `positive`, но далёкие от `negative`). Параметр `topn` отвечает за то, сколько наиболее вероятных (по убыванию вероятности) слов выдавать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6541075706481934)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ожидаем увидеть \"queen\"\n",
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И снова посмотрим на пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.7719833850860596),\n",
       " ('wife', 0.7053205966949463),\n",
       " ('grandmother', 0.7014738917350769)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ожидаем \"mother\"\n",
    "model.wv.most_similar(['girl', 'father'], ['boy'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше примеров соотношения слов в векторном пространстве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'he' соотносится с 'his' также, как 'she' соотносится с 'her'\n",
      "'big' соотносится с 'bigger' также, как 'bad' соотносится с 'worse'\n",
      "'going' соотносится с 'went' также, как 'being' соотносится с 'was'\n"
     ]
    }
   ],
   "source": [
    "more_examples = [\"he his she\", \n",
    "                 \"big bigger bad\", \n",
    "                 \"going went being\"]\n",
    "\n",
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.wv.most_similar([x, b], [a])[0][0]\n",
    "    print(\"'%s' соотносится с '%s' также, как '%s' соотносится с '%s'\" % (a, b, x, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель также умеет находить слова, которые не подходят \"по смыслу\" другим словам из данной последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# по порядку: \"завтрак\" \"зерновой\" \"обед\" \"ланч\"\n",
    "model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы можем сохранить модель (матрицу весов (эмбеддингов)), чтобы потом можно было её переиспользовать, если нужно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 02:49:22,021 : INFO : saving Word2Vec object under text8.model, separately None\n",
      "2018-03-07 02:49:22,023 : INFO : not storing attribute syn0norm\n",
      "2018-03-07 02:49:22,025 : INFO : storing np array 'syn0' to text8.model.wv.syn0.npy\n",
      "2018-03-07 02:49:22,855 : INFO : not storing attribute cum_table\n",
      "2018-03-07 02:49:22,856 : INFO : storing np array 'syn1neg' to text8.model.syn1neg.npy\n",
      "2018-03-07 02:49:23,759 : INFO : saved text8.model\n"
     ]
    }
   ],
   "source": [
    "model.save('text8.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем указать и другой формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 02:49:43,596 : INFO : storing 71290x200 projection weights into text8.model.bin\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('text8.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь можно ещё поиграться с Word2Vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Примечание:*   \n",
    "С установкой glove на Windows могут быть трудности (у автора они тоже возникли), но если получится установить, то следующий код должен отработать и вы увидите примеры работы GloVe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(itertools.islice(Text8Corpus('./data/text8'), None))\n",
    "\n",
    "# Специальный класс для корпуса в GloVe\n",
    "corpus = Corpus()\n",
    "corpus.fit(sentences, window=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация класса.   \n",
    "`num_components` - размерность эмбеддинга,  \n",
    "`learning_rate` - вам должно быть уже знакомо ;) (скорость обучения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = Glove(no_components=100, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение словаря в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('frog', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('girl', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " glove.most_similar('car', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('queen', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь можно ещё поиграться с GloVe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезые ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В интернете достаточно много примеров работы с Word2Vec. Вот некоторые из них:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Официальный tutorial от создателей gensim: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "* Tutorial по построению мини-web-приложения на основе Word2Vec: https://rare-technologies.com/word2vec-tutorial/\n",
    "* Визуалцизация Word2Vec-эмбеддингов с помощью Tensorboard (нужен установленная библиотека глубокого обучения **tensorflow** для запуска у себя на компьютере, или просто можно посмотреть, ак оно на видео): https://www.youtube.com/watch?time_continue=181&v=BkeQzJt0f5A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nojupyter]",
   "language": "python",
   "name": "conda-env-nojupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
